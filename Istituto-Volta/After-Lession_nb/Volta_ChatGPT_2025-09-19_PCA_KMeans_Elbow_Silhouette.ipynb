{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b890cc2",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 📘 بصری‌سازی با PCA و انتخاب k در K-Means (Elbow & Silhouette) — جلسه 19/09/2025\n",
    "\n",
    "در این نوت‌بوک، محتوای درس امروز را «گام‌به‌گام و عملی» گردآوری کرده‌ایم:\n",
    "- ساخت دیتاست‌های مصنوعی (`make_blobs`, `make_moons`) برای تمرین.\n",
    "- نرمال‌سازی با `StandardScaler` و چراییِ آن.\n",
    "- تحلیل مؤلفه‌های اصلی (**PCA**) برای بصری‌سازی/کاهش‌بُعد و توضیح «واریانس توضیح‌داده‌شده».\n",
    "- خوشه‌بندی با **K-Means** و انتخاب تعداد خوشه‌ها با دو معیار **Elbow (Inertia)** و **Silhouette**.\n",
    "- فرهنگ واژگان (اصطلاحات فنی ↔ ترجمهٔ فارسی).\n",
    "- «سؤالات تشریحی» برای سنجش فهم کامل درس.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# کتابخانه‌ها\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# برای نمایش تمیزتر نمودارها\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0b53f",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 🎯 مرحله ۱: ساخت دیتاست‌های مصنوعی\n",
    "\n",
    "اینجا دو دیتاست متفاوت می‌سازیم تا رفتار روش‌های خطی و غیرخطی را ببینیم:\n",
    "- **Blobs**: خوشه‌های تقریباً کروی و جداشدنی؛ برای تمرین K-Means ایدئال است.\n",
    "- **Moons**: دو هلال درهم‌تنیده با ساختار **غیرخطی**؛ جایی که K-Means و PCA خطی محدودیت دارند.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e29d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ساخت دیتاست‌ها (قابل تکرار با random_state)\n",
    "X_blob, y_blob = make_blobs(\n",
    "    n_samples=500, centers=4,\n",
    "    cluster_std=[1.2, 1.0, 0.8, 1.1],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_moon, y_moon = make_moons(\n",
    "    n_samples=500, noise=0.08, random_state=42\n",
    ")\n",
    "\n",
    "print('Shapes -> blob:', X_blob.shape, 'moons:', X_moon.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c120832",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 🧭 مرحله ۲: نرمال‌سازی ویژگی‌ها با StandardScaler (چراییِ حیاتی)\n",
    "\n",
    "**PCA** و **K-Means** هر دو مبتنی بر **فاصله**‌اند؛ بنابراین «مقیاس ویژگی‌ها» اثر مستقیم دارد.\n",
    "با `StandardScaler` هر بُعد را به «میانگین صفر، انحراف معیار یک» می‌بریم تا همهٔ ابعاد **عادلانه** در محاسبات مشارکت کنند.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# اسکیلِ مستقل برای هر دیتاست\n",
    "scaler_blob = StandardScaler()\n",
    "X_blob_s = scaler_blob.fit_transform(X_blob)\n",
    "\n",
    "scaler_moon = StandardScaler()\n",
    "X_moon_s = scaler_moon.fit_transform(X_moon)\n",
    "\n",
    "X_blob_s[:3], X_moon_s[:3]  # پیش‌نمایش سه ردیف اول\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da489c8",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 🔎 مرحله ۳: PCA — ایده، کارکرد، واریانسِ توضیح‌داده‌شده\n",
    "\n",
    "**PCA** محورهایی ارتوگونال می‌یابد که **بیشترین واریانس** داده روی آن‌هاست؛ سپس داده را روی این محورها تصویر می‌کند.\n",
    "- چون هر دو دیتاست ما «دو-بعدی» هستند، `n_components=2` صرفاً یک **چرخش/تغییر مقیاس** ایجاد می‌کند (کاهش‌بُعد واقعی رخ نمی‌دهد).\n",
    "- با این حال، برای بصری‌سازی، **همان ۲ مؤلفه** را رسم می‌کنیم و «نسبت واریانسِ توضیح‌داده‌شده» را نیز می‌بینیم.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56682167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PCA روی blob (دو مؤلفه)\n",
    "pca_blob = PCA(n_components=2, random_state=42)\n",
    "B2 = pca_blob.fit_transform(X_blob_s)\n",
    "\n",
    "print('Explained variance ratio (blob):', pca_blob.explained_variance_ratio_,\n",
    "      'sum =', pca_blob.explained_variance_ratio_.sum())\n",
    "\n",
    "# نمودار PCA برای blob (یک نمودار در یک شکل)\n",
    "plt.figure()\n",
    "plt.scatter(B2[:, 0], B2[:, 1], s=10, c=y_blob)\n",
    "plt.title('PCA Visualization — Blobs')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b75dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PCA روی moons (دو مؤلفه)\n",
    "pca_moon = PCA(n_components=2, random_state=42)\n",
    "M2 = pca_moon.fit_transform(X_moon_s)\n",
    "\n",
    "print('Explained variance ratio (moons):', pca_moon.explained_variance_ratio_,\n",
    "      'sum =', pca_moon.explained_variance_ratio_.sum())\n",
    "\n",
    "# نمودار PCA برای moons (یک نمودار در یک شکل)\n",
    "plt.figure()\n",
    "plt.scatter(M2[:, 0], M2[:, 1], s=10, c=y_moon)\n",
    "plt.title('PCA Visualization — Moons')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602418ab",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 📊 مرحله ۴: K-Means و انتخاب k با Elbow و Silhouette\n",
    "\n",
    "هدف: برای چند مقدار مختلفِ \\(k\\)، K-Means را اجرا کنیم و کیفیت خوشه‌بندی را با\n",
    "- **Inertia (SSE)** برای روش **Elbow**\n",
    "- **Silhouette** برای تعادل «چسبندگی درون‌خوشه‌ای/جدایی بین‌خوشه‌ای»\n",
    "بسنجیم و بهترین \\(k\\) را انتخاب کنیم.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elbow_silhouette(X, kmin=2, kmax=10, random_state=42, n_init=10):\n",
    "    \"\"\"\n",
    "    اجرای K-Means برای kهای مختلف و محاسبهٔ Inertia و Silhouette.\n",
    "    خروجی: (لیست kها، لیست اینرسی‌ها، لیست سیلوئت‌ها)\n",
    "    \"\"\"\n",
    "    ks = list(range(kmin, kmax + 1))\n",
    "    inertia, sils = [], []\n",
    "    for k in ks:\n",
    "        kmeans = KMeans(n_clusters=k, n_init=n_init, random_state=random_state)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "        sils.append(silhouette_score(X, labels))\n",
    "    return ks, inertia, sils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# اجرای معیارها روی blob\n",
    "ks_b, inertia_b, sils_b = elbow_silhouette(X_blob_s, 2, 10)\n",
    "\n",
    "# Elbow (inertia)\n",
    "plt.figure()\n",
    "plt.plot(ks_b, inertia_b, marker='o')\n",
    "plt.xlabel('k'); plt.ylabel('Inertia (SSE)'); plt.title('Elbow — Blobs')\n",
    "plt.show()\n",
    "\n",
    "# Silhouette\n",
    "plt.figure()\n",
    "plt.plot(ks_b, sils_b, marker='s')\n",
    "plt.xlabel('k'); plt.ylabel('Silhouette (mean)'); plt.title('Silhouette — Blobs')\n",
    "plt.show()\n",
    "\n",
    "best_k_sil = ks_b[int(np.argmax(sils_b))]\n",
    "print('Best k by Silhouette (blobs):', best_k_sil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d129243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# اجرای معیارها روی moons (برای مشاهدهٔ محدودیت K-Means در ساختار غیرخطی)\n",
    "ks_m, inertia_m, sils_m = elbow_silhouette(X_moon_s, 2, 10)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ks_m, inertia_m, marker='o')\n",
    "plt.xlabel('k'); plt.ylabel('Inertia (SSE)'); plt.title('Elbow — Moons')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ks_m, sils_m, marker='s')\n",
    "plt.xlabel('k'); plt.ylabel('Silhouette (mean)'); plt.title('Silhouette — Moons')\n",
    "plt.show()\n",
    "\n",
    "best_k_sil_m = ks_m[int(np.argmax(sils_m))]\n",
    "print('Best k by Silhouette (moons):', best_k_sil_m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d75264",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 🧾 فرهنگ واژگان (اصطلاحات فنی ↔ ترجمهٔ فارسی)\n",
    "\n",
    "- **Dataset** = مجموعه‌داده  \n",
    "- **Feature / Dimension** = ویژگی / بُعد  \n",
    "- **Standardization** = استانداردسازی (میانگین صفر، انحراف معیار یک)  \n",
    "- **PCA (Principal Component Analysis)** = تحلیل مؤلفه‌های اصلی  \n",
    "- **Principal Component (PC)** = مؤلفهٔ اصلی  \n",
    "- **Explained Variance Ratio** = نسبت واریانسِ توضیح‌داده‌شده  \n",
    "- **Projection** = تصویر/پروژکشن روی فضا/محورها  \n",
    "- **Clustering** = خوشه‌بندی  \n",
    "- **K-Means** = خوشه‌بندی k-میانگین  \n",
    "- **Centroid** = مرکز خوشه  \n",
    "- **Inertia (SSE)** = اینرسی / مجموع مربعات خطا تا نزدیک‌ترین مرکز  \n",
    "- **Elbow Method** = روش آرنج  \n",
    "- **Silhouette Score** = امتیاز سیلوئت  \n",
    "- **Within-Cluster Distance** = فاصلهٔ درون‌خوشه‌ای  \n",
    "- **Between-Cluster Separation** = جدایی بین‌خوشه‌ای  \n",
    "- **Nonlinear Structure** = ساختار غیرخطی  \n",
    "- **Kernel Methods** = روش‌های هسته‌ای (برای نگاشت به فضای ویژگی با بُعد بالاتر)  \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab591af0",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 📝 سؤالات تشریحی (نشانهٔ فهم کامل)\n",
    "\n",
    "1) چرا قبل از اجرای **PCA** و **K-Means** باید داده را استاندارد کنیم؟ دقیقاً چه مشکلی رخ می‌دهد اگر این کار را نکنیم؟  \n",
    "2) در دادهٔ دو-بعدی، اجرای `PCA(n_components=2)` چه اثری دارد و چرا «کاهش‌بُعد واقعی» محسوب نمی‌شود؟  \n",
    "3) تعریف دقیق امتیاز **Silhouette** برای یک نقطه چیست؟ رابطهٔ آن با \\(a(i)\\) و \\(b(i)\\) را بنویسید و تفسیر عددی آن را توضیح دهید.  \n",
    "4) چرا روش **Elbow** همیشه کاهش اینرسی را نشان می‌دهد و چگونه «نقطهٔ آرنج» را تشخیص می‌دهیم؟ محدودیت‌های این روش چیست؟  \n",
    "5) برای دیتاست **moons** چرا K-Means انتخاب مناسبی نیست؟ چه الگوریتم‌ها/روش‌های جایگزینی را پیشنهاد می‌کنید و چرا؟  \n",
    "6) اگر در خروجی سیلوئت، بهترین \\(k\\) عدد بزرگی شد ولی یک خوشه فقط چند نقطه داشت، چه نتیجه‌ای می‌گیرید و چه اقداماتی پیشنهاد می‌شود؟  \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf888112",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" align=\"right\">\n",
    "\n",
    "# 📚 منابع جلسه\n",
    "\n",
    "- **Hands-On Machine Learning (Géron)** — فصل «کاهش بُعد (PCA)» و فصل «یادگیری بدون ناظر: خوشه‌بندی (K-Means)»  \n",
    "- **Pattern Recognition and Machine Learning (Bishop)** — فصل «Continuous Latent Variables» (بخش PCA)  \n",
    "- **Scikit-learn User Guide** — بخش‌های `PCA`, `KMeans`, `silhouette_score`  \n",
    "- **Effective Python (Slatkin)** — نکات بهترین‌عمل‌کرد در سازمان‌دهی کد و آزمایش‌پذیری  \n",
    "\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
